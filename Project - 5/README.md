![Uploading Screenshot 2026-02-20 150657.pngâ€¦]()










# ğŸ˜Š Real-Time Facial Emotion Detection

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/OpenCV-27338e?style=for-the-badge&logo=OpenCV&logoColor=white"/>
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"/>
  <img src="https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge"/>
</p>

<p align="center">
  A deep learning-powered application that detects and classifies human emotions in real-time using a webcam feed. Built with OpenCV for face detection and a pre-trained Keras model for emotion classification.
</p>

---

## ğŸ“¸ Demo

> Real-time detection of emotions directly from webcam or video input â€” with bounding boxes and emotion labels rendered on each detected face.

---

## âœ¨ Features

- ğŸ¥ **Real-time detection** from live webcam feed
- ğŸ§  **Deep Learning model** (`.hdf5`) trained to classify facial emotions
- ğŸ‘¤ **Face detection** using Haar Cascade Classifier (`haarcascade_frontalface_default.xml`)
- ğŸ“Š **7 Emotion classes**: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
- âš¡ Fast and lightweight â€” runs efficiently on standard hardware

---

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ emotion_detection.py          # Main script for real-time emotion detection
â”œâ”€â”€ emotion_model.hdf5            # Pre-trained Keras deep learning model
â”œâ”€â”€ haarcascade_frontalface_default.xml  # OpenCV Haar Cascade for face detection
â””â”€â”€ README.md
```

---

## ğŸ§  How It Works

1. **Face Detection** â€” OpenCV's Haar Cascade classifier scans each video frame and identifies face regions.
2. **Preprocessing** â€” Detected face ROIs (Regions of Interest) are extracted, converted to grayscale, resized to `48Ã—48` pixels, and normalized.
3. **Emotion Prediction** â€” The preprocessed face is passed into the pre-trained Keras CNN model (`emotion_model.hdf5`), which outputs probability scores across 7 emotion categories.
4. **Visualization** â€” The predicted emotion label and confidence are overlaid on the original video frame with a bounding box around the detected face.

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|---|---|
| Python | Core programming language |
| OpenCV (`cv2`) | Face detection & video frame processing |
| TensorFlow / Keras | Loading and running the emotion classification model |
| NumPy | Array manipulation and preprocessing |

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/Programmer-surajit123/real-time-emotion-detection.git
cd real-time-emotion-detection
```

### 2. Install Dependencies

```bash
pip install opencv-python tensorflow numpy
```

> **Python 3.8+** is recommended. You can also use a virtual environment:
> ```bash
> python -m venv venv
> source venv/bin/activate   # On Windows: venv\Scripts\activate
> pip install opencv-python tensorflow numpy
> ```

### 3. Run the Application

```bash
python emotion_detection.py
```

Press **`Q`** to quit the webcam window.

---

## ğŸ“¦ Requirements

```
opencv-python>=4.5
tensorflow>=2.6
numpy>=1.19
```

---

## ğŸ¯ Emotion Classes

The model is trained to detect the following **7 emotions**:

| Label | Emotion |
|---|---|
| 0 | ğŸ˜  Angry |
| 1 | ğŸ¤¢ Disgust |
| 2 | ğŸ˜¨ Fear |
| 3 | ğŸ˜Š Happy |
| 4 | ğŸ˜ Neutral |
| 5 | ğŸ˜¢ Sad |
| 6 | ğŸ˜² Surprise |

---

## ğŸš€ Future Improvements

- [ ] Add support for video file input
- [ ] Display a real-time emotion probability bar chart
- [ ] Build a web app interface using Flask or Streamlit
- [ ] Improve model accuracy with a larger dataset
- [ ] Add multi-face tracking support

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open an issue or submit a pull request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Surajit Das**

<p>
  <a href="https://github.com/Programmer-surajit123">
    <img src="https://img.shields.io/badge/GitHub-Programmer--surajit123-181717?style=for-the-badge&logo=github&logoColor=white"/>
  </a>
  &nbsp;
  <a href="https://www.linkedin.com/in/surajit-das-04142533b/">
    <img src="https://img.shields.io/badge/LinkedIn-Surajit%20Das-0077B5?style=for-the-badge&logo=linkedin&logoColor=white"/>
  </a>
</p>

---

<p align="center">â­ If you found this project helpful, please give it a star!</p>
